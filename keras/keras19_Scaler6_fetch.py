import time
import pandas as pd #
import numpy as np
from sklearn import datasets
from sklearn.datasets import fetch_covtype
#from tensorflow.keras.utils import to_categorical # 값 백터수를 맞춰주는 api # 0값부터 연산
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, MaxAbsScaler
from tensorflow.python.keras.backend import relu
#from sklearn.preprocessing import OneHotEncoder # 0~7까지 출력

#1. 데이터
datasets = fetch_covtype()
x = datasets.data
y = datasets.target
#y = to_categorical(y) 
'''
ohe = OneHotEncoder(sparse=False) # 1부터 끝값까지 출력한다.
y = ohe.fit_transform(y.reshape(-1, 1))
'''
y = pd.get_dummies(y) # 0데이터값을 빼고 그 다음부터 연산
x_train, x_test, y_train, y_test = train_test_split(x, y,
        train_size=0.8, shuffle=True, random_state=66)
# print(x_train.shape,y_train.shape)
# print(x_test.shape,y_test.shape)
# print(y[0:10])
scaler = MaxAbsScaler()
scaler.fit(x_train)
x_train = scaler.transform(x_train)
x_test = scaler.transform(x_test)

#2. 모델구성
model = Sequential()
model.add(Dense(70, activation = 'linear', input_dim = 54))# linear= 기본값
model.add(Dense(50, activation = 'linear'))
model.add(Dense(30, activation = 'relu'))
model.add(Dense(10, activation = 'linear'))
model.add(Dense(7, activation = 'softmax'))

#3. 컴파일, 훈련
model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])  # metrics 몇개가 맞았는지 결과값을 보기위해 씀
                                                                                       
es = EarlyStopping(monitor='val_loss', patience=20, mode = 'auto')
start = time.time()
hist = model.fit(x_train, y_train, epochs=100, batch_size = 54, validation_split = 0.2 , callbacks = [es], verbose = 1)
end = time.time()- start

print("걸린시간 : ", round(end, 3), '초')

#4. 평가, 예측
loss = model.evaluate(x_test, y_test)
print('loss: ', loss[0])
print('accuracy : ', loss[1])

results = model.predict(x_test[:7])
print(y_test[:7])
print(results)
'''
# 기본값
loss:  0.6489388942718506
accuracy :  0.7218143939971924
        1  2  3  4  5  6  7
257457  1  0  0  0  0  0  0
15362   0  1  0  0  0  0  0
455621  1  0  0  0  0  0  0
26237   0  1  0  0  0  0  0
530518  0  1  0  0  0  0  0
2113    0  1  0  0  0  0  0
81459   0  1  0  0  0  0  0
[[7.1946639e-01 2.5779215e-01 9.2284775e-09 4.0918327e-13 4.3074178e-04
  2.4906013e-08 2.2310687e-02]
 [6.2859714e-02 9.3550587e-01 1.1091341e-05 2.3200228e-08 1.3616865e-03
  2.5500622e-04 6.5858567e-06]
 [7.8569335e-01 2.0234053e-01 2.8171834e-07 6.6956345e-12 9.3322119e-04
  1.0332654e-05 1.1022276e-02]
 [7.5098373e-02 9.1947758e-01 2.8350638e-05 8.9870895e-07 4.9514514e-03
  3.8529467e-04 5.8024132e-05]
 [4.8064578e-01 5.0665468e-01 5.2525088e-06 6.1202243e-10 2.1985220e-03
  6.5251065e-06 1.0489182e-02]
 [2.7789906e-01 7.0697868e-01 3.1820000e-06 3.6017255e-12 1.4992694e-02
  5.3167634e-05 7.3240044e-05]
 [1.9191703e-01 8.0730152e-01 2.0562522e-06 6.5680217e-09 4.5427453e-04
  1.2139729e-05 3.1301103e-04]]
'''
'''
# MinMaxScaler
loss:  0.6328110098838806
accuracy :  0.7237851023674011
        1  2  3  4  5  6  7
257457  1  0  0  0  0  0  0
15362   0  1  0  0  0  0  0
455621  1  0  0  0  0  0  0
26237   0  1  0  0  0  0  0
530518  0  1  0  0  0  0  0
2113    0  1  0  0  0  0  0
81459   0  1  0  0  0  0  0
[[7.5758344e-01 1.8224734e-01 3.1634848e-09 2.7642268e-14 3.7555513e-04
  5.7635439e-09 5.9793569e-02]
 [7.1108676e-02 9.2866224e-01 1.7209875e-05 3.6132161e-07 1.0587010e-04
  1.0019776e-04 5.4529928e-06]
 [8.2288617e-01 1.7063269e-01 2.0419769e-07 1.8341141e-10 2.1703701e-04
  1.9445120e-05 6.2444163e-03]
 [7.2636060e-02 9.2358941e-01 6.5216431e-05 4.2795196e-05 3.2221174e-03
  4.2128866e-04 2.3059321e-05]
 [5.3333646e-01 4.5317140e-01 1.0589539e-06 7.6092306e-11 2.4305913e-03
  9.5215828e-06 1.1050870e-02]
 [2.6169658e-01 7.1125144e-01 8.1707403e-06 3.7424599e-12 2.7007503e-02
  3.0927262e-05 5.4238903e-06]
 [1.7670573e-01 8.2256424e-01 7.5920630e-06 9.0060084e-08 4.4311633e-04
  3.0162195e-05 2.4913184e-04]]
'''
'''
# relu를 사용한 MinMaxScaler
loss:  0.4480656385421753
accuracy :  0.8094971776008606
        1  2  3  4  5  6  7
257457  1  0  0  0  0  0  0
15362   0  1  0  0  0  0  0
455621  1  0  0  0  0  0  0
26237   0  1  0  0  0  0  0
530518  0  1  0  0  0  0  0
2113    0  1  0  0  0  0  0
81459   0  1  0  0  0  0  0
[[8.88102055e-01 1.01108007e-01 6.08385954e-13 3.14503805e-25
  7.21227386e-13 3.91645944e-14 1.07899560e-02]
 [4.95227724e-01 5.04655302e-01 4.83842189e-10 7.77119471e-13
  1.07418164e-04 9.54248117e-06 4.23484078e-12]
 [9.27934825e-01 7.20236227e-02 6.03776229e-08 2.76392186e-18
  9.17009690e-10 1.26618801e-07 4.12971131e-05]
 [1.48927003e-01 6.97868049e-01 6.50157335e-06 1.84195270e-13
  1.52989015e-01 2.09384656e-04 3.64897869e-12]
 [2.07064971e-02 9.79260266e-01 2.61127528e-08 1.17541492e-15
  7.47104139e-07 9.07910986e-12 3.24550929e-05]
 [2.46770635e-01 7.40803778e-01 2.66294109e-07 1.98332219e-11
  1.24220224e-02 2.06389245e-06 1.26565715e-06]
 [7.76164308e-02 9.22372580e-01 1.01939477e-05 3.42048138e-18
  3.94300258e-07 3.86518565e-07 7.85161589e-11]]
'''
'''
# StandardScaler
loss:  0.6380148530006409
accuracy :  0.7221586108207703
        1  2  3  4  5  6  7
257457  1  0  0  0  0  0  0
15362   0  1  0  0  0  0  0
455621  1  0  0  0  0  0  0
26237   0  1  0  0  0  0  0
530518  0  1  0  0  0  0  0
2113    0  1  0  0  0  0  0
81459   0  1  0  0  0  0  0
[[6.29804432e-01 2.83520281e-01 6.73504275e-09 3.42729588e-13
  7.80940172e-04 9.88410864e-09 8.58942941e-02]
 [7.27851689e-02 9.26840603e-01 6.31511648e-05 8.82675863e-07
  1.71976630e-04 1.31752458e-04 6.54188898e-06]
 [8.10717165e-01 1.82492629e-01 4.98309760e-07 9.49606060e-10
  3.10501317e-04 3.29639479e-05 6.44621672e-03]
 [7.74711967e-02 9.17946875e-01 1.00911093e-04 7.35025096e-05
  3.89432278e-03 4.83397511e-04 2.97335209e-05]
 [4.25303966e-01 5.61130404e-01 1.91654772e-06 4.01915140e-10
  3.27295088e-03 1.16908614e-05 1.02791227e-02]
 [2.39469722e-01 7.42887795e-01 9.83067366e-06 4.24709122e-11
  1.75867192e-02 4.34058784e-05 2.49786899e-06]
 [1.68959290e-01 8.30084145e-01 1.48777335e-05 2.09529134e-07
  6.04740169e-04 3.39910621e-05 3.02688160e-04]]
'''
'''
# relu를 사용한 StandardScaler
loss:  0.45911866426467896
accuracy :  0.8058397769927979
        1  2  3  4  5  6  7
257457  1  0  0  0  0  0  0
15362   0  1  0  0  0  0  0
455621  1  0  0  0  0  0  0
26237   0  1  0  0  0  0  0
530518  0  1  0  0  0  0  0
2113    0  1  0  0  0  0  0
81459   0  1  0  0  0  0  0
[[9.46821570e-01 3.52717079e-02 9.28465371e-17 5.33131605e-19
  1.04448845e-10 2.54881913e-18 1.79067366e-02]
 [4.23947036e-01 5.76048553e-01 3.98297402e-07 9.61685159e-12
  3.99177543e-06 1.49610067e-08 1.63182168e-14]
 [9.92361903e-01 7.62475934e-03 5.61206116e-12 4.93812031e-08
  1.23202548e-09 1.27760595e-05 4.71956298e-07]
 [3.58340777e-02 9.63967383e-01 2.81607848e-10 3.71908865e-10
  1.91927495e-04 6.68022221e-06 1.83731323e-08]
 [2.83804312e-02 9.71595168e-01 2.16152638e-12 9.53107677e-17
  1.00261263e-06 2.97585409e-14 2.34032959e-05]
 [1.75539292e-02 9.79694664e-01 8.05681793e-07 8.15196799e-09
  1.52154744e-03 3.48340308e-08 1.22901029e-03]
 [1.04315564e-01 8.95684361e-01 4.66739010e-17 8.96766768e-19
  5.56020225e-08 9.53662149e-12 8.30638047e-09]]
'''
'''
# RobustScaler
loss:  0.6339762210845947
accuracy :  0.7227524518966675
        1  2  3  4  5  6  7
257457  1  0  0  0  0  0  0
15362   0  1  0  0  0  0  0
455621  1  0  0  0  0  0  0
26237   0  1  0  0  0  0  0
530518  0  1  0  0  0  0  0
2113    0  1  0  0  0  0  0
81459   0  1  0  0  0  0  0
[[7.6044810e-01 1.9968785e-01 8.4376923e-09 4.4900170e-14 7.1328459e-04
  1.1622416e-08 3.9150786e-02]
 [6.3739933e-02 9.3598330e-01 4.3656717e-05 1.5446484e-07 1.6938415e-04
  5.7427664e-05 6.1494866e-06]
 [8.3682102e-01 1.5789066e-01 5.0740408e-07 6.7446693e-10 2.9304388e-04
  2.9120156e-05 4.9656518e-03]
 [6.2117279e-02 9.3334138e-01 8.7820641e-05 1.4985990e-05 4.2299284e-03
  1.8755057e-04 2.1058529e-05]
 [5.4219186e-01 4.4610843e-01 2.2404297e-06 1.9610411e-10 2.7716837e-03
  1.4145646e-05 8.9115677e-03]
 [2.9910052e-01 6.6105413e-01 7.3933047e-06 3.1840411e-12 3.9815068e-02
  1.8411965e-05 4.4136114e-06]
 [1.4627373e-01 8.5289925e-01 2.3342509e-05 1.2002590e-07 6.0705288e-04
  4.0196534e-05 1.5627815e-04]]
'''
'''
# relu를 사용한 RobustScaler
loss:  0.4430493116378784
accuracy :  0.8100823760032654
        1  2  3  4  5  6  7
257457  1  0  0  0  0  0  0
15362   0  1  0  0  0  0  0
455621  1  0  0  0  0  0  0
26237   0  1  0  0  0  0  0
530518  0  1  0  0  0  0  0
2113    0  1  0  0  0  0  0
81459   0  1  0  0  0  0  0
[[6.2449485e-01 3.5020098e-01 3.0716538e-09 8.0930054e-17 6.0980693e-10
  2.0060591e-08 2.5304154e-02]
 [4.2869776e-02 9.5711523e-01 4.2524371e-07 9.1168020e-14 1.6375368e-09
  1.4472977e-05 1.0219162e-09]
 [9.9859005e-01 1.4082948e-03 2.7695290e-15 1.5370539e-22 3.3499245e-10
  4.7814287e-12 1.6213986e-06]
 [3.8943421e-03 9.4234151e-01 3.4221253e-07 1.1724650e-12 5.3762145e-02
  1.6550723e-06 1.3286626e-09]
 [1.1314765e-02 9.8866898e-01 4.5190525e-17 3.4062663e-27 3.4634038e-06
  1.0233378e-12 1.2782246e-05]
 [1.9852793e-01 7.7999723e-01 3.3271788e-12 6.0329029e-21 2.1435129e-02
  8.5824675e-10 3.9705566e-05]
 [1.8334748e-01 8.1665027e-01 1.3619273e-09 1.6762816e-18 1.4257090e-06
  3.6388284e-10 7.6794987e-07]]
'''
'''
# MaxAbsScaler
loss:  0.63446444272995
accuracy :  0.7248522043228149
        1  2  3  4  5  6  7
257457  1  0  0  0  0  0  0
15362   0  1  0  0  0  0  0
455621  1  0  0  0  0  0  0
26237   0  1  0  0  0  0  0
530518  0  1  0  0  0  0  0
2113    0  1  0  0  0  0  0
81459   0  1  0  0  0  0  0
[[7.78278649e-01 1.74911335e-01 7.10465731e-09 1.31124156e-14
  6.90325920e-04 1.78119812e-08 4.61197272e-02]
 [8.21482465e-02 9.17673826e-01 1.79941962e-05 1.01730571e-08
  1.15718976e-04 2.86163813e-05 1.55696343e-05]
 [8.21055293e-01 1.73897654e-01 6.38690608e-07 1.51446800e-10
  2.42811919e-04 6.17872938e-05 4.74174041e-03]
 [8.20709839e-02 9.14010346e-01 4.98369191e-05 9.71954887e-06
  3.47757898e-03 3.38105310e-04 4.34091271e-05]
 [5.14554620e-01 4.73548263e-01 3.77319657e-06 8.98145516e-11
  3.91364936e-03 3.94538474e-05 7.94014242e-03]
 [3.08475554e-01 6.44451380e-01 3.96307269e-06 3.12340757e-13
  4.70301174e-02 3.43131906e-05 4.80532526e-06]
 [1.85393631e-01 8.13700438e-01 1.07354226e-05 2.44954617e-08
  5.32314123e-04 3.98084230e-05 3.23123764e-04]]
'''
'''
# relu를 사용한 MaxAbsScaler
loss:  0.4481290578842163
accuracy :  0.8110892176628113
        1  2  3  4  5  6  7
257457  1  0  0  0  0  0  0
15362   0  1  0  0  0  0  0
455621  1  0  0  0  0  0  0
26237   0  1  0  0  0  0  0
530518  0  1  0  0  0  0  0
2113    0  1  0  0  0  0  0
81459   0  1  0  0  0  0  0
[[9.87457573e-01 4.60928120e-03 4.38144286e-26 4.62931606e-33
  3.13983301e-12 2.58235034e-17 7.93316495e-03]
 [1.24669224e-01 8.75317872e-01 2.31565656e-09 5.63177648e-19
  1.29529190e-05 5.03325610e-11 2.35256117e-14]
 [9.95494127e-01 4.50091669e-03 1.03367301e-10 1.45357127e-16
  3.58145644e-06 4.70988653e-08 1.31834747e-06]
 [1.06889099e-01 8.89060915e-01 2.55262586e-19 7.87836623e-21
  4.05003037e-03 9.52836421e-11 1.64271499e-10]
 [4.61261906e-02 9.53844249e-01 1.11111810e-16 9.39436756e-22
  2.80993718e-05 3.10634879e-10 1.52025359e-06]
 [1.18338630e-01 8.73755515e-01 3.94438595e-15 1.87316827e-20
  7.90473633e-03 5.94609944e-08 1.01842738e-06]
 [4.72583771e-02 9.52725053e-01 7.44622276e-25 8.34616788e-29
  1.65300353e-05 2.11765758e-13 5.59987751e-11]]
'''